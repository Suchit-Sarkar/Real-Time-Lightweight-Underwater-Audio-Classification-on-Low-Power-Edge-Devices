{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import torchaudio\n",
    "import torchaudio.transforms as T\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from tqdm import tqdm\n",
    "import optuna\n",
    "from torchvggish import vggish"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MarineMammalDataset(Dataset):\n",
    "    def __init__(self, annotation_file, audio_dir, target_sample_rate, num_samples, device, transformation):\n",
    "        self.annotations = pd.read_excel(annotation_file)  # Read Excel metadata\n",
    "        self.audio_dir = audio_dir\n",
    "        self.device = device\n",
    "        self.target_sample_rate = target_sample_rate\n",
    "        self.num_samples = num_samples\n",
    "        self.transformation = transformation.to(self.device)\n",
    "        \n",
    "\n",
    "        # Encode labels as integers\n",
    "        self.label_encoder = LabelEncoder()\n",
    "        self.annotations['species_name'] = self.label_encoder.fit_transform(self.annotations['species_name'])\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.annotations)\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        audio_sample_path = self._get_audio_sample_path(index)\n",
    "        label = self._get_audio_sample_label(index)\n",
    "        #label = label.clone().detach().to(torch.long).to(self.device)\n",
    "\n",
    "        signal, sr = torchaudio.load(audio_sample_path)\n",
    "\n",
    "        # Send to GPU\n",
    "        signal = signal.to(self.device)\n",
    "\n",
    "        # Resample, mix down, cut, and pad\n",
    "        signal = self._resample_if_necessary(signal, sr)\n",
    "        signal = self._mix_down_if_necessary(signal)\n",
    "        signal = self._cut_if_necessary(signal)\n",
    "        signal = self._right_pad_if_necessary(signal)\n",
    "\n",
    "        #Apply some more preprocessing \n",
    "        #signal = self._apply_noise_reduction(signal)\n",
    "        #signal = self._remove_silence(signal)\n",
    "        #signal = self._apply_highpass_filter(signal)\n",
    "        #signal = self._normalize_volume(signal)\n",
    "        #signal = self._clip_waveform(signal)\n",
    "        #signal = self._apply_bandpass_filter(signal)\n",
    "\n",
    "\n",
    "        mel_spec = self.transformation(signal.to(torch.float32))\n",
    "        mel_spec = torch.log(mel_spec + 1e-6)  # Convert to log scale for VGGish\n",
    "\n",
    "        mel_spec = torch.nn.functional.interpolate(\n",
    "            mel_spec.unsqueeze(0), size=(64, 96), mode='bilinear', align_corners=False\n",
    "        ).squeeze(0)\n",
    "\n",
    "        # Ensure 3D shape\n",
    "        mel_spec = mel_spec.unsqueeze(0) if mel_spec.ndim == 2 else mel_spec\n",
    "\n",
    "        # Convert label to tensor\n",
    "        \n",
    "        label = torch.tensor(label, dtype=torch.long).to(self.device)\n",
    "\n",
    "        # Convert label to tensor\n",
    "        #label = torch.tensor(label, dtype=torch.long).to(self.device)\n",
    "        #label = label.clone().detach().to(self.device)\n",
    "        label = torch.tensor(label, dtype=torch.long).clone().detach().to(self.device)\n",
    "\n",
    "        return mel_spec, label\n",
    "    \n",
    "    \n",
    "    def _clip_waveform(self, signal, clip_value=0.99):\n",
    "        return torch.clamp(signal, -clip_value, clip_value)\n",
    "    \n",
    "    def _pitch_shift(self, signal, n_steps=2, sample_rate=16000):\n",
    "        pitch_shifter = T.PitchShift(sample_rate, n_steps=n_steps).to(signal.device)\n",
    "        return pitch_shifter(signal)\n",
    "    \n",
    "    def _apply_bandpass_filter(self, signal):\n",
    "    # Create a compose transformation if you want to apply multiple augmentations\n",
    "        augment = Compose([\n",
    "        HighPassFilter(min_cutoff_freq=10, max_cutoff_freq=240, p=1)\n",
    "        ])\n",
    "    \n",
    "    # Convert signal to numpy for augmentations\n",
    "        signal_np = signal.cpu().numpy().squeeze()\n",
    "    \n",
    "    # Apply augmentation\n",
    "        augmented_signal = augment(signal_np, sample_rate=self.target_sample_rate)\n",
    "    \n",
    "    # Convert back to torch tensor\n",
    "        return torch.tensor(augmented_signal).unsqueeze(0).to(self.device)\n",
    "    \n",
    "    def _normalize_volume(self, signal):\n",
    "        rms = torch.sqrt(torch.mean(signal**2))\n",
    "        normalized_signal = signal / rms\n",
    "        return normalized_signal\n",
    "    def _apply_noise_reduction(self, signal):\n",
    "        noise = signal[:, :16000]  # Assume the first second contains noise\n",
    "        reduced_signal = reduce_noise(\n",
    "        y=signal.cpu().numpy().squeeze(), \n",
    "        sr=16000, \n",
    "        y_noise=noise.cpu().numpy().squeeze()\n",
    "        )\n",
    "        return torch.tensor(reduced_signal).unsqueeze(0).to(signal.device)\n",
    "    \n",
    "    def _remove_silence(self, signal, top_db=30):\n",
    "        signal_np = signal.cpu().numpy().squeeze()\n",
    "        intervals = librosa.effects.split(signal_np, top_db=top_db)\n",
    "        non_silent_signal = np.concatenate([signal_np[start:end] for start, end in intervals])\n",
    "        return torch.tensor(non_silent_signal).unsqueeze(0).to(signal.device)\n",
    "    \n",
    "    def _cut_if_necessary(self, signal):\n",
    "        if signal.shape[1] > self.num_samples:\n",
    "            signal = signal[:, :self.num_samples]\n",
    "        return signal\n",
    "\n",
    "    def _right_pad_if_necessary(self, signal):\n",
    "        if signal.shape[1] < self.num_samples:\n",
    "            num_missing_samples = self.num_samples - signal.shape[1]\n",
    "            last_dim_padding = (0, num_missing_samples)\n",
    "            signal = torch.nn.functional.pad(signal, last_dim_padding)\n",
    "        return signal\n",
    "\n",
    "    def _resample_if_necessary(self, signal, sr):\n",
    "        if sr != self.target_sample_rate:\n",
    "            resampler = torchaudio.transforms.Resample(sr, self.target_sample_rate).to(self.device)\n",
    "            signal = resampler(signal)\n",
    "        return signal\n",
    "\n",
    "    def _mix_down_if_necessary(self, signal):\n",
    "        if signal.shape[0] > 1:\n",
    "            signal = torch.mean(signal, dim=0, keepdim=True)\n",
    "        return signal\n",
    "    \n",
    "    def _get_audio_sample_path(self, index):\n",
    "        file_name = self.annotations.iloc[index, 0]  # file_name column\n",
    "        path = os.path.join(self.audio_dir, file_name)\n",
    "        return os.path.normpath(path)\n",
    "\n",
    "    def _get_audio_sample_label(self, index):\n",
    "        return self.annotations.iloc[index, 2]  # Encoded species_name column\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_annotation_file = \"E:/Project_Experiments/9_species_experiment/New_Test_2025/train_metadata.xlsx\"\n",
    "train_audio_dir = \"E:/Project_Experiments/9_species_experiment/New_Test_2025/train\"\n",
    "test_annotation_file = \"E:/Project_Experiments/9_species_experiment/New_Test_2025/test_metadata.xlsx\"\n",
    "test_audio_dir = \"E:/Project_Experiments/9_species_experiment/New_Test_2025/test\"\n",
    "validate_annotation_file = \"E:/Project_Experiments/9_species_experiment/New_Test_2025/validate_metadata.xlsx\"\n",
    "validate_audio_dir = \"E:/Project_Experiments/9_species_experiment/New_Test_2025/validate\"\n",
    "\n",
    "# VGGish-specific configurations\n",
    "    \n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "sample_rate = 16000  # Required sample rate for VGGish\n",
    "num_samples = sample_rate * 5  # 5 seconds of audio at 16 kHz\n",
    "mel_spectrogram = torchaudio.transforms.MelSpectrogram(\n",
    "        sample_rate=sample_rate,\n",
    "        n_fft=400,  # Smaller window size for VGGish\n",
    "        hop_length=160,  # Matches VGGish expectation\n",
    "        n_mels=64\n",
    "    )\n",
    "\n",
    "    # Create the dataset\n",
    "train_dataset = MarineMammalDataset(train_annotation_file, train_audio_dir, sample_rate, num_samples, device, mel_spectrogram)\n",
    "train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)\n",
    "test_dataset = MarineMammalDataset(test_annotation_file, test_audio_dir, sample_rate, num_samples, device, mel_spectrogram)\n",
    "test_loader = DataLoader(test_dataset, batch_size=32, shuffle=True)\n",
    "validate_dataset = MarineMammalDataset(validate_annotation_file, validate_audio_dir, sample_rate, num_samples, device, mel_spectrogram)\n",
    "val_loader = DataLoader(validate_dataset, batch_size=32, shuffle=True)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sequential(\n",
      "  (0): Linear(in_features=12288, out_features=4096, bias=True)\n",
      "  (1): LayerNorm((4096,), eps=1e-05, elementwise_affine=True)\n",
      "  (2): ReLU()\n",
      "  (3): Dropout(p=0.3, inplace=False)\n",
      "  (4): Linear(in_features=4096, out_features=2048, bias=True)\n",
      "  (5): LayerNorm((2048,), eps=1e-05, elementwise_affine=True)\n",
      "  (6): ReLU()\n",
      "  (7): Dropout(p=0.3, inplace=False)\n",
      "  (8): Linear(in_features=2048, out_features=1024, bias=True)\n",
      "  (9): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
      "  (10): ReLU()\n",
      "  (11): Dropout(p=0.3, inplace=False)\n",
      "  (12): Linear(in_features=1024, out_features=512, bias=True)\n",
      "  (13): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
      "  (14): ReLU()\n",
      "  (15): Dropout(p=0.3, inplace=False)\n",
      "  (16): Linear(in_features=512, out_features=256, bias=True)\n",
      "  (17): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
      "  (18): ReLU()\n",
      "  (19): Dropout(p=0.3, inplace=False)\n",
      "  (20): Linear(in_features=256, out_features=9, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "    # Initialize the VGGish model\n",
    "model = vggish().to(device)\n",
    "    #print(model)\n",
    "\n",
    "# Move PCA tensors to the same device as the model\n",
    "if model.postprocess:\n",
    " model.pproc._pca_matrix = model.pproc._pca_matrix.to(device)\n",
    " model.pproc._pca_means = model.pproc._pca_means.to(device)\n",
    "\n",
    "input_tensor = torch.rand(1, 1, 96, 64).to(device)\n",
    "output = model(input_tensor)\n",
    "    #print(f\"Old Output : \", output)\n",
    "    #summary(model, (1, 96, 64))\n",
    "    # # Path to the pretrained weights\n",
    "pretrained_weights_path = \"C:/Users/myair/.cache/torch/hub/checkpoints/vggish-10086976.pth\"\n",
    "\n",
    "    # # Load pretrained weights\n",
    "model.load_state_dict(torch.load(pretrained_weights_path, map_location=device, weights_only=True), strict=False)\n",
    "    # # Freeze pretrained feature extractor layers\n",
    "for param in model.features.parameters():\n",
    " param.requires_grad = False\n",
    "num_classes = 9\n",
    "\n",
    "for param in list(model.features[-5:].parameters()):  # Accessing the last  layers\n",
    " param.requires_grad = True\n",
    "    \n",
    "def create_fc(num_inputs,num_layers,neuron_per_layer,num_outputs,dropout_rate):\n",
    " layers=[]\n",
    " for i in range(num_layers):\n",
    "  layers.append(nn.Linear(num_inputs,neuron_per_layer))\n",
    "  layers.append(nn.LayerNorm(neuron_per_layer))\n",
    "  layers.append(nn.ReLU())\n",
    "  layers.append(nn.Dropout(dropout_rate, inplace=False))\n",
    "  num_inputs=neuron_per_layer\n",
    "  neuron_per_layer=num_inputs//2\n",
    "\n",
    " layers.append(nn.Linear(num_inputs,num_outputs))\n",
    " #Create the sequential layer \n",
    " fc=nn.Sequential(*layers)\n",
    " return fc\n",
    "fc=create_fc(12288,5,4096,9,0.3)\n",
    "print(fc)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def new_forward(x):\n",
    " with torch.set_grad_enabled(True):\n",
    "  x = model.features(x)  # Extract features\n",
    "  x = x.view(x.size(0), -1)  # Flatten the feature map\n",
    "  x = model.fc(x)  # Pass through the updated classifier\n",
    " return x\n",
    "\n",
    "def objective(trial):\n",
    "        \n",
    "        # 1. Using optuna generate number of hidden layers\n",
    "        num_hidden_layers=trial.suggest_int(\"num_hidden_layers\", 1, 5)\n",
    "        # 2. Using optuna generate number of neurons per layer\n",
    "        neurons_per_layer=trial.suggest_int(\"neurons_per_layer\", 512,8192,step=512)\n",
    "        # 3. Using optuna generate number of epochs\n",
    "        num_epochs=trial.suggest_int(\"Epochs\",4,12,step=2)\n",
    "        # 4. Using optuna generate learning rate\n",
    "        learning_rate=trial.suggest_float(\"Learning rate\",1e-5,1e-3,log=True)\n",
    "        # 5. Using optuna generate dropout rate\n",
    "        dropout_rate=trial.suggest_float(\"Dropout_rate\",0.1,0.5,step=0.1)\n",
    "        # 6. Using optuna generate batch size\n",
    "        batch_size=trial.suggest_categorical(\"batch_size\", [16,32,64])\n",
    "        # 7. Using optuna generate optimizer name\n",
    "        optimizer_name=trial.suggest_categorical(\"Optimizer\", ['Adam','SGD','RMSprop'])\n",
    "        # 8. Using optuna generate weight decay\n",
    "        weight_decay=trial.suggest_float(\"Weight decay\",1e-5,1e-3,log=True)\n",
    "        # initialize/update the model now\n",
    "        model.fc=create_fc(12288,num_hidden_layers, neurons_per_layer,num_classes,dropout_rate).to(device)\n",
    "        criterion = nn.CrossEntropyLoss()\n",
    "        #optimizer = optim.Adam(model.parameters(), lr=(1e-5)*4)\n",
    "        if optimizer_name=='Adam':\n",
    "            optimizer = optim.Adam(model.parameters(), lr=learning_rate, weight_decay=weight_decay)\n",
    "        elif optimizer_name=='SGD':\n",
    "            optimizer = optim.SGD(model.parameters(), lr=learning_rate, weight_decay=weight_decay)\n",
    "        else:\n",
    "            optimizer = optim.RMSprop(model.parameters(), lr=learning_rate, weight_decay=weight_decay)\n",
    "        \n",
    "        model.forward=new_forward\n",
    "        train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "        test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)\n",
    "        torch.autograd.set_detect_anomaly(True)\n",
    "        #Training loop\n",
    "        for epochs in range(num_epochs):\n",
    "            model.train()\n",
    "            running_loss = 0.0\n",
    "            correct_predictions = 0\n",
    "            total_samples = 0\n",
    "\n",
    "            for inputs, labels in train_loader:\n",
    "                inputs, labels = inputs.to(device), labels.to(device)\n",
    "\n",
    "                # Forward pass\n",
    "                outputs = model(inputs)\n",
    "                loss = criterion(outputs, labels)\n",
    "\n",
    "                # Backward pass\n",
    "                optimizer.zero_grad()\n",
    "                loss.backward()\n",
    "                optimizer.step()\n",
    "\n",
    "                # Update metrics\n",
    "                #running_loss += loss.item() * inputs.size(0)\n",
    "                _, preds = torch.max(outputs, 1)\n",
    "                correct_predictions += (preds == labels).sum().item()\n",
    "                total_samples += labels.size(0)\n",
    "\n",
    "            #epoch_loss = running_loss / len(train_loader.dataset)\n",
    "            epoch_accuracy = correct_predictions / total_samples\n",
    "        print(\" Training accuracy :\",epoch_accuracy)\n",
    "\n",
    "        #Test loop : return testing accuracy: Need to maximize\n",
    "        model.eval()\n",
    "        correct=0\n",
    "        total=0\n",
    "\n",
    "        with torch.no_grad():\n",
    "            for inputs, labels in test_loader:\n",
    "                inputs, labels = inputs.to(device), labels.to(device)\n",
    "\n",
    "            # Forward pass\n",
    "                outputs = model(inputs)\n",
    "                _, preds = torch.max(outputs, 1)\n",
    "\n",
    "            \n",
    "            # Count correct predictions\n",
    "                correct += (preds == labels).sum().item()\n",
    "                total += labels.size(0)\n",
    "        test_accuracy=correct/total*100\n",
    "        return test_accuracy\n",
    "\n",
    "    # # Save the fine-tuned model\n",
    "    # torch.save(model, \"E:/Project_Experiments/9_species_experiment/New_Test_2025/fine_tuned_marine_mammal_vggish.pth\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-02-08 18:49:02,897] A new study created in memory with name: no-name-4f5e2658-f649-492f-bbe7-5bacba2f516b\n",
      "C:\\Users\\myair\\AppData\\Local\\Temp\\ipykernel_1944\\4109140043.py:60: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  label = torch.tensor(label, dtype=torch.long).clone().detach().to(self.device)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Training accuracy : 0.20286659316427783\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-02-08 18:53:30,095] Trial 0 finished with value: 43.06393244873342 and parameters: {'num_hidden_layers': 4, 'neurons_per_layer': 8192, 'Epochs': 4, 'Learning rate': 0.0009958936867781058, 'Dropout_rate': 0.5, 'batch_size': 64, 'Optimizer': 'SGD', 'Weight decay': 3.459022339340795e-05}. Best is trial 0 with value: 43.06393244873342.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Training accuracy : 0.996141124586549\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-02-08 19:07:50,901] Trial 1 finished with value: 86.24849215922798 and parameters: {'num_hidden_layers': 5, 'neurons_per_layer': 6144, 'Epochs': 8, 'Learning rate': 4.607573491164103e-05, 'Dropout_rate': 0.30000000000000004, 'batch_size': 16, 'Optimizer': 'Adam', 'Weight decay': 0.0006344478983149422}. Best is trial 1 with value: 86.24849215922798.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Training accuracy : 0.9727122381477398\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-02-08 19:15:51,011] Trial 2 finished with value: 86.12786489746684 and parameters: {'num_hidden_layers': 5, 'neurons_per_layer': 6656, 'Epochs': 4, 'Learning rate': 0.00038198771811713734, 'Dropout_rate': 0.2, 'batch_size': 64, 'Optimizer': 'Adam', 'Weight decay': 2.593135144318663e-05}. Best is trial 1 with value: 86.24849215922798.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Training accuracy : 0.9986218302094818\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-02-08 19:22:00,071] Trial 3 finished with value: 84.07720144752714 and parameters: {'num_hidden_layers': 4, 'neurons_per_layer': 3584, 'Epochs': 6, 'Learning rate': 0.00010522141751643215, 'Dropout_rate': 0.1, 'batch_size': 32, 'Optimizer': 'RMSprop', 'Weight decay': 5.455179221516757e-05}. Best is trial 1 with value: 86.24849215922798.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Training accuracy : 0.9980705622932745\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-02-08 19:35:04,215] Trial 4 finished with value: 88.05790108564536 and parameters: {'num_hidden_layers': 5, 'neurons_per_layer': 1024, 'Epochs': 10, 'Learning rate': 6.904599704334791e-05, 'Dropout_rate': 0.4, 'batch_size': 16, 'Optimizer': 'Adam', 'Weight decay': 0.0002838749061654009}. Best is trial 4 with value: 88.05790108564536.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Training accuracy : 0.9691289966923925\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-02-08 19:39:32,981] Trial 5 finished with value: 85.52472858866103 and parameters: {'num_hidden_layers': 1, 'neurons_per_layer': 2048, 'Epochs': 4, 'Learning rate': 0.0008653620247278095, 'Dropout_rate': 0.2, 'batch_size': 16, 'Optimizer': 'Adam', 'Weight decay': 1.0191571086200156e-05}. Best is trial 4 with value: 88.05790108564536.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Training accuracy : 0.9953142227122381\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-02-08 19:53:32,850] Trial 6 finished with value: 90.10856453558505 and parameters: {'num_hidden_layers': 2, 'neurons_per_layer': 5120, 'Epochs': 12, 'Learning rate': 0.0003154523365200716, 'Dropout_rate': 0.2, 'batch_size': 16, 'Optimizer': 'SGD', 'Weight decay': 0.0009255666600033805}. Best is trial 6 with value: 90.10856453558505.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Training accuracy : 0.5283902976846747\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-02-08 19:58:49,436] Trial 7 finished with value: 76.7189384800965 and parameters: {'num_hidden_layers': 4, 'neurons_per_layer': 3584, 'Epochs': 6, 'Learning rate': 0.00016290130552062471, 'Dropout_rate': 0.4, 'batch_size': 32, 'Optimizer': 'SGD', 'Weight decay': 2.1858509223883854e-05}. Best is trial 6 with value: 90.10856453558505.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Training accuracy : 0.9983461962513782\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-02-08 20:10:09,172] Trial 8 finished with value: 91.31483715319662 and parameters: {'num_hidden_layers': 4, 'neurons_per_layer': 1024, 'Epochs': 12, 'Learning rate': 4.795339902956599e-05, 'Dropout_rate': 0.5, 'batch_size': 32, 'Optimizer': 'Adam', 'Weight decay': 2.4332071091028467e-05}. Best is trial 8 with value: 91.31483715319662.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Training accuracy : 0.9776736493936052\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-02-08 20:33:28,481] Trial 9 finished with value: 90.59107358262968 and parameters: {'num_hidden_layers': 5, 'neurons_per_layer': 512, 'Epochs': 12, 'Learning rate': 6.033394993955948e-05, 'Dropout_rate': 0.30000000000000004, 'batch_size': 64, 'Optimizer': 'RMSprop', 'Weight decay': 2.7157985860286698e-05}. Best is trial 8 with value: 91.31483715319662.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Training accuracy : 0.9983461962513782\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-02-08 20:42:30,091] Trial 10 finished with value: 89.98793727382389 and parameters: {'num_hidden_layers': 3, 'neurons_per_layer': 2048, 'Epochs': 10, 'Learning rate': 1.0954334115483946e-05, 'Dropout_rate': 0.5, 'batch_size': 32, 'Optimizer': 'Adam', 'Weight decay': 0.00014518394957425395}. Best is trial 8 with value: 91.31483715319662.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Training accuracy : 0.9994487320837927\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-02-08 20:52:39,889] Trial 11 finished with value: 91.43546441495778 and parameters: {'num_hidden_layers': 3, 'neurons_per_layer': 512, 'Epochs': 12, 'Learning rate': 2.9961526451147717e-05, 'Dropout_rate': 0.4, 'batch_size': 64, 'Optimizer': 'RMSprop', 'Weight decay': 1.0269702547456945e-05}. Best is trial 11 with value: 91.43546441495778.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Training accuracy : 0.9994487320837927\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-02-08 21:02:09,011] Trial 12 finished with value: 91.43546441495778 and parameters: {'num_hidden_layers': 3, 'neurons_per_layer': 2048, 'Epochs': 12, 'Learning rate': 1.883082213141984e-05, 'Dropout_rate': 0.4, 'batch_size': 64, 'Optimizer': 'RMSprop', 'Weight decay': 1.1669642313350815e-05}. Best is trial 11 with value: 91.43546441495778.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Training accuracy : 0.9997243660418964\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-02-08 21:09:51,271] Trial 13 finished with value: 91.79734620024126 and parameters: {'num_hidden_layers': 2, 'neurons_per_layer': 2560, 'Epochs': 10, 'Learning rate': 1.6403990527209376e-05, 'Dropout_rate': 0.4, 'batch_size': 64, 'Optimizer': 'RMSprop', 'Weight decay': 1.092318676668115e-05}. Best is trial 13 with value: 91.79734620024126.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Training accuracy : 0.9994487320837927\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-02-08 21:17:52,430] Trial 14 finished with value: 91.91797346200241 and parameters: {'num_hidden_layers': 2, 'neurons_per_layer': 3072, 'Epochs': 10, 'Learning rate': 2.2175208722064758e-05, 'Dropout_rate': 0.4, 'batch_size': 64, 'Optimizer': 'RMSprop', 'Weight decay': 7.888853024533711e-05}. Best is trial 14 with value: 91.91797346200241.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Training accuracy : 0.9994487320837927\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-02-08 21:25:42,803] Trial 15 finished with value: 92.15922798552472 and parameters: {'num_hidden_layers': 1, 'neurons_per_layer': 3584, 'Epochs': 10, 'Learning rate': 1.1011305896876287e-05, 'Dropout_rate': 0.30000000000000004, 'batch_size': 64, 'Optimizer': 'RMSprop', 'Weight decay': 9.970738182608503e-05}. Best is trial 15 with value: 92.15922798552472.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Training accuracy : 0.9997243660418964\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-02-08 21:33:41,180] Trial 16 finished with value: 92.15922798552472 and parameters: {'num_hidden_layers': 1, 'neurons_per_layer': 4608, 'Epochs': 8, 'Learning rate': 1.015762453028712e-05, 'Dropout_rate': 0.30000000000000004, 'batch_size': 64, 'Optimizer': 'RMSprop', 'Weight decay': 9.897764669598588e-05}. Best is trial 15 with value: 92.15922798552472.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Training accuracy : 0.9994487320837927\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-02-08 21:41:03,923] Trial 17 finished with value: 92.52110977080821 and parameters: {'num_hidden_layers': 1, 'neurons_per_layer': 4608, 'Epochs': 8, 'Learning rate': 1.1262002620627131e-05, 'Dropout_rate': 0.30000000000000004, 'batch_size': 64, 'Optimizer': 'RMSprop', 'Weight decay': 0.00016046101455048314}. Best is trial 17 with value: 92.52110977080821.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Training accuracy : 0.9994487320837927\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-02-08 21:50:06,926] Trial 18 finished with value: 92.40048250904704 and parameters: {'num_hidden_layers': 1, 'neurons_per_layer': 5632, 'Epochs': 8, 'Learning rate': 3.040311240152974e-05, 'Dropout_rate': 0.1, 'batch_size': 64, 'Optimizer': 'RMSprop', 'Weight decay': 0.00020787765814208456}. Best is trial 17 with value: 92.52110977080821.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Training accuracy : 0.9997243660418964\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-02-08 22:00:00,714] Trial 19 finished with value: 92.40048250904704 and parameters: {'num_hidden_layers': 1, 'neurons_per_layer': 5632, 'Epochs': 8, 'Learning rate': 3.313787706327997e-05, 'Dropout_rate': 0.1, 'batch_size': 64, 'Optimizer': 'RMSprop', 'Weight decay': 0.00021397511787444326}. Best is trial 17 with value: 92.52110977080821.\n"
     ]
    }
   ],
   "source": [
    "study=optuna.create_study(direction='maximize')\n",
    "study.optimize(objective, n_trials=20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
